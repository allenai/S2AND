{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Welcome to the S2AND tutorial!\n",
    "\n",
    "We will cover a few aspects of the S2AND pipeline:\n",
    "\n",
    "(1) Load a test dataset.\n",
    "(2) Fit a pairwise model + bells & whistles.\n",
    "(3) Fit a clusterer.\n",
    "(4) Evaluate the pairwise model and the clusterer.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "\n",
    "import json\n",
    "import copy\n",
    "import argparse\n",
    "import logging\n",
    "import pickle\n",
    "from typing import Dict, Any, Optional, List\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from s2and.data import PDData\n",
    "from s2and.featurizer import featurize, FeaturizationInfo\n",
    "from s2and.model import PairwiseModeler, Clusterer, FastCluster\n",
    "from s2and.eval import pairwise_eval, cluster_eval, facet_eval\n",
    "from s2and.consts import FEATURIZER_VERSION, DEFAULT_CHUNK_SIZE, PROJECT_ROOT_PATH\n",
    "from s2and.file_cache import cached_path\n",
    "from s2and.plotting_utils import plot_facets\n",
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the random seed we used for the ablations table\n",
    "random_seed = 42\n",
    "# number of cpus to use\n",
    "n_jobs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 19:15:38,114 - s2and - INFO - loading papers\n",
      "2022-10-10 19:15:38,129 - s2and - INFO - loaded papers\n",
      "2022-10-10 19:15:38,130 - s2and - INFO - loading clusters\n",
      "2022-10-10 19:15:38,132 - s2and - INFO - loaded clusters, loading specter\n",
      "2022-10-10 19:15:38,133 - s2and - INFO - loaded specter, loading cluster seeds\n",
      "2022-10-10 19:15:38,134 - s2and - INFO - loaded cluster seeds\n",
      "2022-10-10 19:15:38,135 - s2and - INFO - making paper to cluster id\n",
      "2022-10-10 19:15:38,136 - s2and - INFO - made paper to cluster id\n",
      "2022-10-10 19:15:38,137 - s2and - INFO - preprocessing papers\n",
      "Preprocessing papers: 100%|██████████| 356/356 [00:00<00:00, 767.56it/s]\n",
      "2022-10-10 19:15:38,730 - s2and - INFO - preprocessed papers\n"
     ]
    }
   ],
   "source": [
    "# we're going to load the arnetminer dataset\n",
    "# and assume that you have it already downloaded to the `S2AND/data/` directory\n",
    "\n",
    "dataset_name = 'test'\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT_PATH, 'data')\n",
    "\n",
    "pddata = PDData(\n",
    "    papers=os.path.join(DATA_DIR, dataset_name + \"_papers.json\"),\n",
    "    name=dataset_name,\n",
    "    mode=\"train\",  # can also be 'inference' if just predicting\n",
    "    clusters=os.path.join(DATA_DIR, dataset_name + \"_clusters.json\"),\n",
    "    train_pairs=None,  # in case you have predefined splits for the pairwise models\n",
    "    val_pairs=None,\n",
    "    test_pairs=None,\n",
    "    train_pairs_size=100000,  # how many training pairs for the pairwise models?\n",
    "    val_pairs_size=10000,\n",
    "    test_pairs_size=10000,\n",
    "    n_jobs=n_jobs,\n",
    "    load_name_counts=False,\n",
    "    random_seed=random_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 19:15:40,569 - s2and - INFO - featurizing train\n",
      "2022-10-10 19:15:40,571 - s2and - INFO - Creating 214 pieces of work\n",
      "2022-10-10 19:15:40,573 - s2and - INFO - Created pieces of work\n",
      "2022-10-10 19:15:40,574 - s2and - INFO - Cached changed, doing 214 work in parallel\n",
      "2022-10-10 19:15:40,695 - s2and - INFO - Work completed\n",
      "2022-10-10 19:15:40,697 - s2and - INFO - Making numpy arrays for features and labels\n",
      "2022-10-10 19:15:40,699 - s2and - INFO - Numpy arrays made\n",
      "2022-10-10 19:15:40,701 - s2and - INFO - featurized train, featurizing val\n",
      "2022-10-10 19:15:40,702 - s2and - INFO - Creating 28 pieces of work\n",
      "2022-10-10 19:15:40,704 - s2and - INFO - Created pieces of work\n",
      "2022-10-10 19:15:40,705 - s2and - INFO - Cached changed, doing 28 work in parallel\n",
      "2022-10-10 19:15:40,823 - s2and - INFO - Work completed\n",
      "2022-10-10 19:15:40,826 - s2and - INFO - Making numpy arrays for features and labels\n",
      "2022-10-10 19:15:40,827 - s2and - INFO - Numpy arrays made\n",
      "2022-10-10 19:15:40,829 - s2and - INFO - featurized val, featurizing test\n",
      "2022-10-10 19:15:40,831 - s2and - INFO - Creating 21 pieces of work\n",
      "2022-10-10 19:15:40,832 - s2and - INFO - Created pieces of work\n",
      "2022-10-10 19:15:40,837 - s2and - INFO - Cached changed, doing 21 work in parallel\n",
      "2022-10-10 19:15:40,957 - s2and - INFO - Work completed\n",
      "2022-10-10 19:15:40,959 - s2and - INFO - Making numpy arrays for features and labels\n",
      "2022-10-10 19:15:40,961 - s2and - INFO - Numpy arrays made\n",
      "2022-10-10 19:15:40,963 - s2and - INFO - featurized test\n"
     ]
    }
   ],
   "source": [
    "# to train the pairwise model, we define which feature categories to use\n",
    "# here it is all of them\n",
    "features_to_use = [\n",
    "    \"author_similarity\",\n",
    "    \"venue_similarity\",\n",
    "    \"year_diff\",\n",
    "    \"title_similarity\",\n",
    "    \"abstract_similarity\",\n",
    "]\n",
    "\n",
    "# we store all the information about the features in this convenient wrapper\n",
    "featurization_info = FeaturizationInfo(features_to_use=features_to_use, featurizer_version=FEATURIZER_VERSION)\n",
    "\n",
    "# now we can actually go and get the pairwise training, val and test data\n",
    "train, val, test = featurize(pddata, featurization_info, n_jobs=4, use_cache=False, chunk_size=DEFAULT_CHUNK_SIZE, nan_value=np.nan)  # type: ignore\n",
    "X_train, y_train, nameless_X_train = train\n",
    "X_val, y_val, nameless_X_val = val\n",
    "X_test, y_test, nameless_X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 12.97trial/s, best loss: -0.875] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hyperopt.base.Trials at 0x7f0efe151198>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we define and fit the pairwise modelers\n",
    "pairwise_modeler = PairwiseModeler(\n",
    "    n_iter=25,  # number of hyperparameter search iterations\n",
    "    estimator=None,  # this will use the default LightGBM classifier\n",
    "    search_space=None,  # this will use the default LightGBM search space\n",
    "    monotone_constraints=featurization_info.lightgbm_monotone_constraints,  # we use monotonicity constraints to make the model more sensible\n",
    "    random_state=random_seed,\n",
    ")\n",
    "pairwise_modeler.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 19:15:46,048 - s2and - INFO - Fitting clusterer\n",
      "2022-10-10 19:15:46,081 - s2and - INFO - Making 1 distance matrices\n",
      "2022-10-10 19:15:46,082 - s2and - INFO - Initializing pairwise_probas\n",
      "2022-10-10 19:15:46,083 - s2and - INFO - Pairwise probas initialized, starting making all pairs\n",
      "2022-10-10 19:15:46,084 - s2and - INFO - Featurizing batch 0/1\n",
      "2022-10-10 19:15:46,085 - s2and - INFO - Getting constraints\n",
      "2022-10-10 19:15:46,086 - s2and - INFO - Creating 120 pieces of work\n",
      "2022-10-10 19:15:46,089 - s2and - INFO - Created pieces of work\n",
      "2022-10-10 19:15:46,089 - s2and - INFO - Cached changed, doing 120 work in parallel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 1695 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 19:15:46,209 - s2and - INFO - Work completed\n",
      "2022-10-10 19:15:46,212 - s2and - INFO - Making numpy arrays for features and labels\n",
      "2022-10-10 19:15:46,214 - s2and - INFO - Numpy arrays made\n",
      "2022-10-10 19:15:46,215 - s2and - INFO - Making predict flags\n",
      "2022-10-10 19:15:46,216 - s2and - INFO - Pairwise classification\n",
      "2022-10-10 19:15:46,220 - s2and - INFO - Starting to make matrices\n",
      "Writing matrices: 100%|██████████| 120/120 [00:00<00:00, 261735.04it/s]\n",
      "2022-10-10 19:15:46,223 - s2and - INFO - 1 distance matrices made\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 406.12trial/s, best loss: -0.597]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 19:15:46,291 - s2and - INFO - Clusterer fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<s2and.model.Clusterer at 0x7f0ead6ba7f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can fit the clusterer itself\n",
    "clusterer = Clusterer(\n",
    "    featurization_info,\n",
    "    pairwise_modeler.classifier,  # the actual pairwise classifier\n",
    "    cluster_model=FastCluster(linkage='average'),  # average linkage agglomerative clustering\n",
    "    search_space={\"eps\": hp.uniform(\"choice\", 0, 1)},  # the hyperparemetrs for the clustering algorithm\n",
    "    n_jobs=n_jobs,\n",
    "    use_cache=False,\n",
    "    random_state=random_seed,\n",
    ")\n",
    "clusterer.fit(pddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C extension was not built during install!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "All-NaN slice encountered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUROC': 1.0, 'Average Precision': 1.0, 'F1': 1.0, 'Precision': 1.0, 'Recall': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# but how good are our models? \n",
    "# first, let's look at the quality of the pairwise evaluation\n",
    "pairwise_metrics = pairwise_eval(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    pairwise_modeler,\n",
    "    os.path.join(PROJECT_ROOT_PATH, \"data\", \"tutorial_figures\"),  # where to put the figures\n",
    "    \"tutorial_figures\",  # what to call the figures\n",
    "    featurization_info.get_feature_names(),\n",
    "    skip_shap=False,  # if your model isn't a tree-based model, you should put True here and it will not make SHAP figures\n",
    ")\n",
    "print(pairwise_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 19:15:53,995 - s2and - INFO - Making 1 distance matrices\n",
      "2022-10-10 19:15:53,996 - s2and - INFO - Initializing pairwise_probas\n",
      "2022-10-10 19:15:53,997 - s2and - INFO - Pairwise probas initialized, starting making all pairs\n",
      "2022-10-10 19:15:53,998 - s2and - INFO - Featurizing batch 0/1\n",
      "2022-10-10 19:15:53,999 - s2and - INFO - Getting constraints\n",
      "2022-10-10 19:15:54,000 - s2and - INFO - Creating 153 pieces of work\n",
      "2022-10-10 19:15:54,002 - s2and - INFO - Created pieces of work\n",
      "2022-10-10 19:15:54,005 - s2and - INFO - Cached changed, doing 153 work in parallel\n",
      "2022-10-10 19:15:54,134 - s2and - INFO - Work completed\n",
      "2022-10-10 19:15:54,136 - s2and - INFO - Making numpy arrays for features and labels\n",
      "2022-10-10 19:15:54,138 - s2and - INFO - Numpy arrays made\n",
      "2022-10-10 19:15:54,140 - s2and - INFO - Making predict flags\n",
      "2022-10-10 19:15:54,141 - s2and - INFO - Pairwise classification\n",
      "2022-10-10 19:15:54,146 - s2and - INFO - Starting to make matrices\n",
      "Writing matrices: 100%|██████████| 153/153 [00:00<00:00, 155835.00it/s]\n",
      "2022-10-10 19:15:54,149 - s2and - INFO - 1 distance matrices made\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B3 (P, R, F1)': (0.595, 1.0, 0.746), 'Pred bigger ratio (mean, count)': (1.71, 7), 'True bigger ratio (mean, count)': (nan, 0)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mean of empty slice.\n",
      "invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# we can do the same thing for the clustering performance\n",
    "cluster_metrics, b3_metrics_per_signature = cluster_eval(\n",
    "    pddata,\n",
    "    clusterer,\n",
    "    split=\"test\",  # which part of the data to evaluate on, can also be 'val'\n",
    "    use_s2_clusters=False,  # set to true if you want to see how the old S2 system does\n",
    ")\n",
    "print(cluster_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('s2and')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a324344a38a2b71ef39af09a7448bcf45e5c27cf7a633e909c54afe4cf2573d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
